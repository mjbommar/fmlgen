{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (C) Michael Bommarito, 2022; https://linkedin.com/in/bommarito\n",
    "# SPDX: Apache-2.0\n",
    "\n",
    "# import from the module where most of the code really lives\n",
    "from fml_gpt_neo_model import get_model, get_tokenizer, load_sample, get_dataset, \\\n",
    "    train_model, load_model, generate_fml"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train a model\n",
    "\n",
    "If you want to (re)train a model, you can set `train=True` and execute the following cell.\n",
    "\n",
    "Default model training parameters are set in the `fml_gpt_neo_model` module as follows:\n",
    "* model_version: EleutherAI/gpt-neo-1.3B\n",
    "* token length (for tokenizer with max_length padding): 40\n",
    "* batch size (for training and eval): 2\n",
    "\n",
    "Once trained, the model is saved in `./model`, which is the default path for `load_model`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.2 ms, sys: 15.8 ms, total: 71 ms\n",
      "Wall time: 335 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train: bool = False\n",
    "tokenizer = get_tokenizer()\n",
    "\n",
    "if train:\n",
    "    # get the initial model\n",
    "    model = get_model()\n",
    "\n",
    "    # load the sample\n",
    "    sample_list = list(load_sample(\"../data/sample.txt.xz\", num_samples=5000))\n",
    "\n",
    "    # load the dataset\n",
    "    dataset = get_dataset(sample_list, tokenizer=tokenizer)\n",
    "\n",
    "    # train the model - you probably want more epochs\n",
    "    train_model(dataset, model, tokenizer, epochs=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# now (re)load the model\n",
    "model = load_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Yesterday, I noticed that the electric nose hair clippers I've been using for 3 years now do not detect my smell like bacon cheeseburgers bacon. FML\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate as many samples as requested\n",
    "for sample in generate_fml(model,\n",
    "                           tokenizer,\n",
    "                           num_samples=1,\n",
    "                           temperature=1.0,\n",
    "                           ):\n",
    "    print(f\"- {sample}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Today, I was building an AI model when someone called. I laughed, causing the model to be a little frightened. Two hours later, the model punched me in the face. FML\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now generate one from a prompt\n",
    "prompt = \"Today, I was building an AI model when\"\n",
    "for sample in generate_fml(model,\n",
    "                           tokenizer,\n",
    "                           prompt,\n",
    "                           num_samples=1,\n",
    "                           temperature=1.0\n",
    "                           ):\n",
    "    print(f\"- {sample}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
